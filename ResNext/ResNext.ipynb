{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNext采用VGG网络堆叠的思想以及Inception的split-transform-merge思想，扩展性比较强，可以认为在增加准确率的同时基本不改变或降低模型的复杂度。  \n",
    "\n",
    "#### 卷积范式\n",
    "对于普通的神经元，输入的D个元素会分配到D个分支，进行权重加权，然后进行merge求和，具体过程如下图所示：  \n",
    "![pic1](pic1.png)  \n",
    "用数学公式对上述过程进行归纳，可表示为：$\\displaystyle \\sum^{D}_{i=1}{w_ix_i}$，其中，$x=[x_1,x_2,...,x_D]$为D维的输入向量，$w_i$为对应的第i个分支的权值。上述过程可以被定义为三个过程：spliting, transforming, aggregating：spliting过程将输入向量 $x$ 切片为低维嵌入；transforming过程将得到的低维嵌入进行转换；aggregating过程将得到的转换结果进行聚合。由此，归纳出神经网络的一个通用的单元可以用如下公式进行表示$F(x)=\\displaystyle \\sum^{C}_{i=1}{T_i(x)}$，结合ResNet的identity映射，则带residual结构可用如下公式进行表示：$y=x+\\displaystyle \\sum^{C}_{i=1}{T_i(x)}$。公式中的T变换可以是任意形式，一共有C个独立变换，论文称C为基数，并通过实验，指出基数C对于结果的影响比宽度和深度更加重要。\n",
    "  \n",
    "#### 基本结构\n",
    "如下图，左图是ResNet的基本结构，右图是ResNext的基本结构  \n",
    "![pic0](pic0.png)  \n",
    "对于ResNext的基本结构，可以看到，旁边的residual connection对应公式中的 $x$ ，另一个则是32组独立的同样结构的变换融合后的结果，符合split-transform-merge的模式。下图是文中列出的三个等价结构：  \n",
    "![pic2](pic2.png)  \n",
    "(a)是ResNext的基本单元；将(a)中输出的1x1卷积对concatenate后的feature map统一进行，则得到等价网络结构(b)，(b)和Inception-ResNet的结构相似，不同之处在于其转换的每个分支结构是一致的；进一步将(a)中输入的1x1也合并到一起，则得到网络结构(c)，其中间的3x3卷积通过组卷积进行实现。  \n",
    "  \n",
    "#### 整体网络结构  \n",
    "下图右边一栏是ResNext-50的整体网络架构，其中，4d表示depth，即每一个分组的通道数为4, 32指基数。  \n",
    "![pic3](pic3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对ResNext采用组卷积的方式进行编码实现，我们在实现之前，先对组卷积进行简单介绍：  \n",
    "下图是一般的卷积操作：  \n",
    "![pic4](pic4.png)  \n",
    "对于$H \\times W \\times c_1$的输入，用$c_2$个卷积核对输入进行卷积运算，假设卷积核大小是$3 \\times 3$，且输出的分辨率和输入要求一致，一般卷积的计算过程为：运算过程中卷积核大小为$3 \\times 3 \\times c_1$，每个卷积核和输入的矩阵计算后得到$H \\times W$的输出，$c_2$个卷积核计算后得到的feature map大小为$H \\times W \\times c_2$。  \n",
    "  \n",
    "下图是分组卷积操作：  \n",
    "![pic5](pic5.png)  \n",
    "对于$H \\times W \\times c_1$的输入，假设要得到输出通道为$c_2$，输出分辨率和输入分辨率一致的feature map，卷积核大小为$3 \\times 3$，group设置为2(g)，则分组卷积的计算过程为：首先对输入矩阵在channel维度上进行分组，分成g组，每组的feature map切片大小为$H \\times W \\times \\frac{c_1}{g}$，运算过程中，在每个分组切片上分别进行卷积运算，每个分组切片对应的卷积核大小为$3 \\times 3 \\times \\frac{c_1}{g}$，共有$\\frac{c_2}{g}$个卷积核，计算后，每个分组切片得到的feature map大小为$H \\times W \\times \\frac{c_2}{g}$，最后，对g组的计算结果在channel维度上进行merge，最终得到的eature map大小为$H \\times W \\times c_2$大小的f。 \n",
    "  \n",
    "根据上述过程，我们基于keras对分组卷积进行编码实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分组卷积定义\n",
    "import keras\n",
    "\n",
    "class GroupConv2D(keras.layers.Conv2D):\n",
    "    \"\"\"Group Conv2D\n",
    "\n",
    "    # Arguments\n",
    "        filters: Integer, the dimensionality of the output space\n",
    "            (i.e. the number of output filters in the convolution).\n",
    "            multiple of group\n",
    "        kernel_size: An integer or tuple/list of 2 integers, specifying the\n",
    "            height and width of the 2D convolution window.\n",
    "            Can be a single integer to specify the same value for\n",
    "            all spatial dimensions.\n",
    "        strides: An integer or tuple/list of 2 integers,\n",
    "            specifying the strides of the convolution\n",
    "            along the height and width.\n",
    "            Can be a single integer to specify the same value for\n",
    "            all spatial dimensions.\n",
    "            Specifying any stride value != 1 is incompatible with specifying\n",
    "            any `dilation_rate` value != 1.\n",
    "        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
    "        group: Integer，split feature map into group.\n",
    "        output_padding: An integer or tuple/list of 2 integers,\n",
    "            specifying the amount of padding along the height and width\n",
    "            of the output tensor.\n",
    "            Can be a single integer to specify the same value for all\n",
    "            spatial dimensions.\n",
    "            The amount of output padding along a given dimension must be\n",
    "            lower than the stride along that same dimension.\n",
    "            If set to `None` (default), the output shape is inferred.\n",
    "        data_format: A string,\n",
    "            one of `\"channels_last\"` or `\"channels_first\"`.\n",
    "            The ordering of the dimensions in the inputs.\n",
    "            `\"channels_last\"` corresponds to inputs with shape\n",
    "            `(batch, height, width, channels)` while `\"channels_first\"`\n",
    "            corresponds to inputs with shape\n",
    "            `(batch, channels, height, width)`.\n",
    "            It defaults to the `image_data_format` value found in your\n",
    "            Keras config file at `~/.keras/keras.json`.\n",
    "            If you never set it, then it will be \"channels_last\".\n",
    "        dilation_rate: an integer or tuple/list of 2 integers, specifying\n",
    "            the dilation rate to use for dilated convolution.\n",
    "            Can be a single integer to specify the same value for\n",
    "            all spatial dimensions.\n",
    "            Currently, specifying any `dilation_rate` value != 1 is\n",
    "            incompatible with specifying any stride value != 1.\n",
    "        activation: Activation function to use\n",
    "            (see [activations](../activations.md)).\n",
    "            If you don't specify anything, no activation is applied\n",
    "            (ie. \"linear\" activation: `a(x) = x`).\n",
    "        use_bias: Boolean, whether the layer uses a bias vector.\n",
    "        kernel_initializer: Initializer for the `kernel` weights matrix\n",
    "            (see [initializers](../initializers.md)).\n",
    "        bias_initializer: Initializer for the bias vector\n",
    "            (see [initializers](../initializers.md)).\n",
    "        kernel_regularizer: Regularizer function applied to\n",
    "            the `kernel` weights matrix\n",
    "            (see [regularizer](../regularizers.md)).\n",
    "        bias_regularizer: Regularizer function applied to the bias vector\n",
    "            (see [regularizer](../regularizers.md)).\n",
    "        activity_regularizer: Regularizer function applied to\n",
    "            the output of the layer (its \"activation\").\n",
    "            (see [regularizer](../regularizers.md)).\n",
    "        kernel_constraint: Constraint function applied to the kernel matrix\n",
    "            (see [constraints](../constraints.md)).\n",
    "        bias_constraint: Constraint function applied to the bias vector\n",
    "            (see [constraints](../constraints.md)).\n",
    "\n",
    "    # Input shape\n",
    "        4D tensor with shape:\n",
    "        `(batch, channels, rows, cols)`\n",
    "        if `data_format` is `\"channels_first\"`\n",
    "        or 4D tensor with shape:\n",
    "        `(batch, rows, cols, channels)`\n",
    "        if `data_format` is `\"channels_last\"`.\n",
    "\n",
    "    # Output shape\n",
    "        4D tensor with shape:\n",
    "        `(batch, filters, new_rows, new_cols)`\n",
    "        if `data_format` is `\"channels_first\"`\n",
    "        or 4D tensor with shape:\n",
    "        `(batch, new_rows, new_cols, filters)`\n",
    "        if `data_format` is `\"channels_last\"`.\n",
    "        `rows` and `cols` values might have changed due to padding.\n",
    "        If `output_padding` is specified:\n",
    "\n",
    "        ```\n",
    "        new_rows = ((rows - 1) * strides[0] + kernel_size[0]\n",
    "                    - 2 * padding[0] + output_padding[0])\n",
    "        new_cols = ((cols - 1) * strides[1] + kernel_size[1]\n",
    "                    - 2 * padding[1] + output_padding[1])\n",
    "        ```\n",
    "\n",
    "    # References\n",
    "        https://blog.csdn.net/lyl771857509/article/details/84109695\n",
    "    \"\"\"\n",
    "    def __init__(self, filters,\n",
    "             kernel_size,\n",
    "             strides=(1, 1),\n",
    "             padding='valid',\n",
    "             group=1,\n",
    "             output_padding=None,\n",
    "             data_format=None,\n",
    "             dilation_rate=(1, 1),\n",
    "             activation=None,\n",
    "             use_bias=True,\n",
    "             kernel_initializer='glorot_uniform',\n",
    "             bias_initializer='zeros',\n",
    "             kernel_regularizer=None,\n",
    "             bias_regularizer=None,\n",
    "             activity_regularizer=None,\n",
    "             kernel_constraint=None,\n",
    "             bias_constraint=None,\n",
    "             **kwargs):\n",
    "        super(GroupConv2D, self).__init__(\n",
    "            filters,\n",
    "            kernel_size,\n",
    "            strides=strides,\n",
    "            padding=padding,\n",
    "            data_format=data_format,\n",
    "            dilation_rate=dilation_rate,\n",
    "            activation=activation,\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            **kwargs)\n",
    "    \n",
    "        self.output_padding = output_padding\n",
    "        self.group = group #初始化\n",
    "        if self.output_padding is not None:\n",
    "            self.output_padding = keras.utils.conv_utils.normalize_tuple(\n",
    "                self.output_padding, 2, 'output_padding')\n",
    "            for stride, out_pad in zip(self.strides, self.output_padding):\n",
    "                if out_pad >= stride:\n",
    "                    raise ValueError('Stride ' + str(self.strides) + ' must be '\n",
    "                                     'greater than output padding ' +\n",
    "                                     str(self.output_padding))\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        kernel_shape = self.kernel_size + (input_dim // self.group, self.filters)  #kernel size: (kernel_size[0], kernel_size[1], input_channels, output_channels)\n",
    "\n",
    "        self.kernel = self.add_weight(shape=kernel_shape,\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.filters,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "        # Set input spec.\n",
    "        self.input_spec = keras.engine.base_layer.InputSpec(ndim=self.rank + 2,\n",
    "                                    axes={channel_axis: input_dim})\n",
    "        self.built = True\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        '''\n",
    "        组卷积的具体实现\n",
    "        :param inputs: \n",
    "        :return: \n",
    "        ''' \n",
    "        group_conv = []#保存每组卷积计算featuremap\n",
    "        output_channels = self.filters // self.group  #output channel\n",
    "        if self.data_format == 'channels_first':#theano\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        #对每个group分别进行卷积计算\n",
    "        for i in range(self.group):\n",
    "            if self.data_format == 'channels_first':\n",
    "                x = inputs[:,i*output_channels:(i+1)*output_channels,:,:]\n",
    "            else:\n",
    "                x = inputs[:,:,:,i*output_channels:(i+1)*output_channels]\n",
    "            #kernel shape: (kernel_size[0], kernel_size[1], input_channels, output_channels)\n",
    "            outputs = keras.backend.conv2d(x, self.kernel[:,:,:,i*output_channels:(i+1)*output_channels], self.strides, self.padding, self.data_format, self.dilation_rate)\n",
    "            \n",
    "            if self.use_bias:\n",
    "                outputs = keras.backend.bias_add(outputs, self.bias[i*output_channels:(i+1)*output_channels], self.data_format)          \n",
    "            group_conv.append(outputs)\n",
    "\n",
    "        outputs = keras.backend.concatenate(group_conv, axis=channel_axis)\n",
    "        return outputs\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(keras.layers.Conv2D, self).get_config()\n",
    "        config.pop('rank')\n",
    "        config[\"group\"] = self.group\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其整体网络结构和ResNet类似，对于网络基本结构，包含两种类型：一种是输入输出一致情况下的Identity Block，另一种是输入输出不一致情况下的Convolutional Block，对于输入输出不一致的情况，跳跃连接中通过加入卷积操作，使得输入输出一致。下面是两种结构的代码实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(x, f, filters, group, stage, block, stride=2):\n",
    "    '''\n",
    "    convolutional block\n",
    "    :param x: input tensor (n, W, H, C)\n",
    "    :param f: integer, conv kernel size\n",
    "    :param filters: integer list, the number of filters in the conv layers\n",
    "    :param group: integer, number of group convolution\n",
    "    :param stage: integer, position in the network(naem)\n",
    "    :param block: string, name the layers, position in the network\n",
    "    :param stride: integer, stride params to be usedf\n",
    "    \n",
    "    returns:\n",
    "    :param x: output tensor(n, W, H, C)\n",
    "    '''\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    x_shortcut = x#输入输出不一致\n",
    "    \n",
    "    #conv1\n",
    "    x = keras.layers.convolutional.Conv2D(filters = F1, kernel_size = (1, 1), strides = (stride, stride), padding = 'valid',\n",
    "                                         kernel_initializer = keras.initializers.glorot_uniform(seed=0),\n",
    "                                         name = conv_name_base + '2a')(x)\n",
    "    x = keras.layers.normalization.BatchNormalization(axis = 3, name = bn_name_base + '2a')(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    #conv2 group convolution\n",
    "    x = GroupConv2D(filters = F2, kernel_size = (f, f), strides = (1, 1), padding = 'same', \n",
    "                   kernel_initializer = keras.initializers.glorot_uniform(seed=0),\n",
    "                   name = conv_name_base + '2b')(x)\n",
    "    x = keras.layers.normalization.BatchNormalization(axis = 3, name = bn_name_base + '2b')(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    #conv3\n",
    "    x = keras.layers.convolutional.Conv2D(filters = F3, kernel_size = (1, 1), strides = (1, 1), padding = 'valid',\n",
    "                                         kernel_initializer = keras.initializers.glorot_uniform(seed=0),\n",
    "                                         name = conv_name_base + '2c')(x)\n",
    "    x = keras.layers.normalization.BatchNormalization(axis = 3, name = bn_name_base + '2c')(x)\n",
    "    \n",
    "    #shortcutx\n",
    "    x_shortcut = keras.layers.convolutional.Conv2D(filters = F3, kernel_size = (1, 1), strides = (stride, stride), padding = 'valid',\n",
    "                                                  kernel_initializer = keras.initializers.glorot_uniform(seed=0),\n",
    "                                                  name = conv_name_base + '1')(x_shortcut)\n",
    "    x_shortcut = keras.layers.normalization.BatchNormalization(axis = 3, name = bn_name_base + '1')(x_shortcut)\n",
    "    \n",
    "    #add\n",
    "    x = keras.layers.Add()([x, x_shortcut])\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(x, f, filters, group, stage, block):\n",
    "    '''\n",
    "    identity block\n",
    "    :param x: input tensor (n, W, H, C)\n",
    "    :param f: integer, conv kernel size\n",
    "    :param filters: integer list, the number of filters in the conv layers\n",
    "    :param group: integer, the number of group convolution\n",
    "    :param stage: integer, position in the network(naem)\n",
    "    :param block: string, name the layers, position in the network\n",
    "    \n",
    "    returns:\n",
    "    :param x: output tensor(n, W, H, C)\n",
    "    '''\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    x_shortcut = x#输入输出一致\n",
    "    \n",
    "    #conv1\n",
    "    x = keras.layers.convolutional.Conv2D(filters = F1, kernel_size = (1, 1), strides = (1, 1), padding = 'valid',\n",
    "                                          kernel_initializer = keras.initializers.glorot_uniform(seed=0), \n",
    "                                          name = conv_name_base + '2a')(x)\n",
    "    x = keras.layers.normalization.BatchNormalization(axis = 3, name = bn_name_base + '2a')(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    #conv2\n",
    "    x = GroupConv2D(filters = F2, kernel_size = (f, f), strides = (1, 1), padding = 'same', \n",
    "                   kernel_initializer = keras.initializers.glorot_uniform(seed=0),\n",
    "                   name = conv_name_base + '2b')(x)\n",
    "    x = keras.layers.normalization.BatchNormalization(axis = 3, name = bn_name_base + '2b')(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    #conv3\n",
    "    x = keras.layers.convolutional.Conv2D(filters = F3, kernel_size = (1, 1), strides = (1, 1), padding = 'valid',\n",
    "                                         kernel_initializer = keras.initializers.glorot_uniform(seed=0),\n",
    "                                         name = conv_name_base + '2c')(x)\n",
    "    x = keras.layers.normalization.BatchNormalization(axis = 3, name = bn_name_base + '2c')(x)\n",
    "    \n",
    "    #add\n",
    "    x = keras.layers.Add()([x, x_shortcut])\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于 convolutional_block 和 identity_block 对ResNext50进行代码实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNext50(input_shape=(224,224,3), classes = 1000, use_dropout = True, dropout_rate = 0.2):\n",
    "    '''\n",
    "    resnet50\n",
    "    :param input_shape:  tuple, input tensor shape\n",
    "    :param classes: integer, classes defined by your dataset\n",
    "    :param use_dropout: bool, use dropout or not\n",
    "    :param dropout_rate: float, only valid if use_dropout is true\n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    keras model\n",
    "    \n",
    "    '''\n",
    "    x_input = keras.layers.Input(input_shape)\n",
    "    x = keras.layers.convolutional.ZeroPadding2D(padding = (3, 3))(x_input)\n",
    "    \n",
    "    #stage1\n",
    "    x = keras.layers.convolutional.Conv2D(filters = 64, kernel_size = (7, 7), strides = (2, 2), \n",
    "                                         kernel_initializer = keras.initializers.glorot_uniform(seed=0), name='conv1')(x)#112x112x64\n",
    "    x = keras.layers.normalization.BatchNormalization(axis = 3, name = 'bn_conv1')(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    x = keras.layers.pooling.MaxPooling2D(pool_size = (3, 3), strides = (2, 2))(x)#56x56x64\n",
    "    \n",
    "    #stage2\n",
    "    x = convolutional_block(x = x, f = 3, filters = [128, 128, 256], group = 32, stage = 2, block = 'a', stride = 1)#56x56x256\n",
    "    x = identity_block(x = x, f = 3, filters = [128, 128, 256], group = 32, stage = 2, block = 'b')#56x56x256\n",
    "    x = identity_block(x = x, f = 3, filters = [128, 128, 256], group = 32, stage = 2, block = 'c')#56x56x256\n",
    "    \n",
    "    #stage3\n",
    "    x = convolutional_block(x = x, f = 3, filters = [256, 256, 512], group = 32, stage = 3, block = 'a', stride = 2)#28x28x512\n",
    "    x = identity_block(x = x, f = 3, filters = [256, 256, 512], group = 32, stage = 3, block = 'b')#28x28x512\n",
    "    x = identity_block(x = x, f = 3, filters = [256, 256, 512], group = 32, stage = 3, block = 'c')#28x28x512\n",
    "    x = identity_block(x = x, f = 3, filters = [256, 256, 512], group = 32, stage = 3, block = 'd')#28x28x512\n",
    "    \n",
    "    #stage4\n",
    "    x = convolutional_block(x = x, f = 3, filters = [512, 512, 1024], group = 32, stage = 4, block = 'a', stride = 2)#14x14x1024\n",
    "    x = identity_block(x = x, f = 3, filters = [512, 512, 1024], group = 32, stage = 4, block = 'b')#14x14x1024\n",
    "    x = identity_block(x = x, f = 3, filters = [512, 512, 1024], group = 32, stage = 4, block = 'c')#14x14x1024\n",
    "    x = identity_block(x = x, f = 3, filters = [512, 512, 1024], group = 32, stage = 4, block = 'd')#14x14x1024\n",
    "    x = identity_block(x = x, f = 3, filters = [512, 512, 1024], group = 32, stage = 4, block = 'e')#14x14x1024\n",
    "    x = identity_block(x = x, f = 3, filters = [512, 512, 1024], group = 32, stage = 4, block = 'f')#14x14x1024\n",
    "    \n",
    "    #stage5\n",
    "    x = convolutional_block(x = x, f = 3, filters = [1024, 1024, 2048], group = 32, stage = 5, block = 'a', stride = 2)#7x7x2048\n",
    "    x = identity_block(x = x, f = 3, filters = [1024, 1024, 2048], group = 32, stage = 5, block = 'b')#7x7x2048\n",
    "    x = identity_block(x = x, f = 3, filters = [1024, 1024, 2048], group = 32, stage = 5, block = 'c')#7x7x2048\n",
    "    \n",
    "    #avgpool\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    #dropout\n",
    "    if use_dropout:\n",
    "        x = keras.layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    #FC\n",
    "    x = keras.layers.core.Dense(units = classes, activation='softmax', kernel_initializer='glorot_uniform', name = 'fc' + str(classes))(x)\n",
    "    #create model\n",
    "    model = keras.models.Model(inputs = x_input, outputs = x, name = 'ResNext50')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 230, 230, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 55, 55, 128)  8320        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 55, 55, 128)  512         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 55, 55, 128)  0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (GroupConv2D)    (None, 55, 55, 128)  147584      activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 55, 55, 128)  512         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 55, 55, 128)  0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 55, 55, 256)  33024       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 55, 55, 256)  16640       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 55, 55, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 55, 55, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 55, 55, 256)  0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 55, 55, 128)  32896       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 55, 55, 128)  512         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 55, 55, 128)  0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (GroupConv2D)    (None, 55, 55, 128)  147584      activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 55, 55, 128)  512         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 55, 55, 128)  0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 55, 55, 256)  33024       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 55, 55, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 55, 55, 256)  0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 55, 55, 128)  32896       activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 55, 55, 128)  512         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 55, 55, 128)  0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (GroupConv2D)    (None, 55, 55, 128)  147584      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 55, 55, 128)  512         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 55, 55, 128)  0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 55, 55, 256)  33024       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 55, 55, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 55, 55, 256)  0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 256)  65792       activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 256)  1024        res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 28, 28, 256)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (GroupConv2D)    (None, 28, 28, 256)  590080      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 256)  1024        res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 28, 28, 256)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  131584      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 28, 28, 512)  0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 256)  131328      activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 256)  1024        res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 28, 28, 256)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (GroupConv2D)    (None, 28, 28, 256)  590080      activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 256)  1024        res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 28, 28, 256)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  131584      activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 28, 28, 512)  0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 256)  131328      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 256)  1024        res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 28, 28, 256)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (GroupConv2D)    (None, 28, 28, 256)  590080      activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 256)  1024        res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 28, 28, 256)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  131584      activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 28, 28, 512)  0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 256)  131328      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 256)  1024        res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 28, 28, 256)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (GroupConv2D)    (None, 28, 28, 256)  590080      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 256)  1024        res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 28, 28, 256)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  131584      activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 28, 28, 512)  0           add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 512)  262656      activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 512)  2048        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 14, 14, 512)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (GroupConv2D)    (None, 14, 14, 512)  2359808     activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 512)  2048        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 14, 14, 512)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 525312      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 14, 14, 1024) 0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 512)  524800      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 512)  2048        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 14, 14, 512)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (GroupConv2D)    (None, 14, 14, 512)  2359808     activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 512)  2048        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 14, 14, 512)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 525312      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 14, 14, 1024) 0           add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 512)  524800      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 512)  2048        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 14, 14, 512)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (GroupConv2D)    (None, 14, 14, 512)  2359808     activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 512)  2048        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 14, 14, 512)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 525312      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 14, 14, 1024) 0           add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 512)  524800      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 512)  2048        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 14, 14, 512)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (GroupConv2D)    (None, 14, 14, 512)  2359808     activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 512)  2048        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 14, 14, 512)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 525312      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 14, 14, 1024) 0           add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 512)  524800      activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 512)  2048        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 14, 14, 512)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (GroupConv2D)    (None, 14, 14, 512)  2359808     activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 512)  2048        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 14, 14, 512)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 525312      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 14, 14, 1024) 0           add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 512)  524800      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 512)  2048        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 14, 14, 512)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (GroupConv2D)    (None, 14, 14, 512)  2359808     activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 512)  2048        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 14, 14, 512)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 525312      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 14, 14, 1024) 0           add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 1024)   1049600     activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 1024)   4096        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 7, 7, 1024)   0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (GroupConv2D)    (None, 7, 7, 1024)   9438208     activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 1024)   4096        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 7, 7, 1024)   0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   2099200     activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 7, 7, 2048)   0           add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 1024)   2098176     activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 1024)   4096        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 7, 7, 1024)   0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (GroupConv2D)    (None, 7, 7, 1024)   9438208     activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 1024)   4096        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 7, 7, 1024)   0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   2099200     activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 7, 7, 2048)   0           add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 1024)   2098176     activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 1024)   4096        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 7, 7, 1024)   0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (GroupConv2D)    (None, 7, 7, 1024)   9438208     activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 1024)   4096        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 7, 7, 1024)   0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   2099200     activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 7, 7, 2048)   0           add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 2048)         0           activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2048)         0           global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "fc1000 (Dense)                  (None, 1000)         2049000     dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 68,985,576\n",
      "Trainable params: 68,917,352\n",
      "Non-trainable params: 68,224\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = ResNext50()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献  \n",
    "(1) Xie S, Girshick R, Dollár P, et al. Aggregated residual transformations for deep neural networks[C]//Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on. IEEE, 2017: 5987-5995.  \n",
    "(2) 深度学习——分类之ResNext https://zhuanlan.zhihu.com/p/32913695  \n",
    "(3) 对深度可分离卷积、分组卷积、扩张卷积、转置卷积（反卷积）的理解 https://blog.csdn.net/Chaolei3/article/details/79374563"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
